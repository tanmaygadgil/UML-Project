{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanma\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# pd.set_option(\"display.max_colwidth\", 200)\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import gzip\n",
    "import spacy\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import os.path\n",
    "from gensim import corpora\n",
    "from gensim.models import LsiModel\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.read_csv('./data/reviews.csv')\n",
    "review_df.drop(columns=['Unnamed: 0'], inplace= True)\n",
    "\n",
    "review_df['user_id'].nunique()\n",
    "\n",
    "review_df['review_text'].fillna('', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>date_added</th>\n",
       "      <th>date_updated</th>\n",
       "      <th>read_at</th>\n",
       "      <th>started_at</th>\n",
       "      <th>n_votes</th>\n",
       "      <th>n_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5805</td>\n",
       "      <td>4cbecbc15af3db041a8e0f594c642bb5</td>\n",
       "      <td>58f2301bd2d4bbfc1b51e4e5fb161cfe</td>\n",
       "      <td>5</td>\n",
       "      <td>Remember, remember, the fifth of November. Thi...</td>\n",
       "      <td>Wed Jun 13 17:55:53 -0700 2012</td>\n",
       "      <td>Mon Jan 30 05:58:01 -0800 2017</td>\n",
       "      <td>Thu Jun 14 00:00:00 -0700 2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5805</td>\n",
       "      <td>49cc59f1c479d698507627b401d47ecf</td>\n",
       "      <td>761a17f52538341a085b629a316204a1</td>\n",
       "      <td>4</td>\n",
       "      <td>Tinha apontado este livro como um dos que tinh...</td>\n",
       "      <td>Sun Jan 05 03:27:10 -0800 2014</td>\n",
       "      <td>Tue Oct 28 15:58:20 -0700 2014</td>\n",
       "      <td>Tue Oct 28 15:58:20 -0700 2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5805</td>\n",
       "      <td>5f03864c758bfceb6d7d5e93eeb20044</td>\n",
       "      <td>ac54c3ce0c9f660c03881b0668f79c60</td>\n",
       "      <td>5</td>\n",
       "      <td>Review coming soon! www.youtube.com/ReadTomes</td>\n",
       "      <td>Tue Feb 12 11:38:36 -0800 2013</td>\n",
       "      <td>Tue Feb 12 12:00:47 -0800 2013</td>\n",
       "      <td>Tue Feb 12 12:00:47 -0800 2013</td>\n",
       "      <td>Tue Feb 12 00:00:00 -0800 2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5805</td>\n",
       "      <td>c309dff1695ed8558b29ea8dcd7479b8</td>\n",
       "      <td>0da0bcc469c2acd15350f9a8f0a74e2b</td>\n",
       "      <td>5</td>\n",
       "      <td>What better way to celebrate Guy Fawkes Day, t...</td>\n",
       "      <td>Tue May 20 09:52:36 -0700 2014</td>\n",
       "      <td>Thu Mar 16 09:49:11 -0700 2017</td>\n",
       "      <td>Wed Nov 05 14:22:10 -0800 2014</td>\n",
       "      <td>Wed Nov 05 00:00:00 -0800 2014</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5805</td>\n",
       "      <td>0f6b8c04f811e05c8978bd6b66ce7685</td>\n",
       "      <td>7d670b6c8cac0c086e21ae2f1af6eccb</td>\n",
       "      <td>4</td>\n",
       "      <td>To note - I am writing this review a quarter c...</td>\n",
       "      <td>Tue Jul 03 16:43:26 -0700 2012</td>\n",
       "      <td>Fri Feb 27 14:46:00 -0800 2015</td>\n",
       "      <td>Tue Jan 01 00:00:00 -0800 1991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    book_id                           user_id  \\\n",
       "6      5805  4cbecbc15af3db041a8e0f594c642bb5   \n",
       "8      5805  49cc59f1c479d698507627b401d47ecf   \n",
       "10     5805  5f03864c758bfceb6d7d5e93eeb20044   \n",
       "12     5805  c309dff1695ed8558b29ea8dcd7479b8   \n",
       "13     5805  0f6b8c04f811e05c8978bd6b66ce7685   \n",
       "\n",
       "                           review_id  rating  \\\n",
       "6   58f2301bd2d4bbfc1b51e4e5fb161cfe       5   \n",
       "8   761a17f52538341a085b629a316204a1       4   \n",
       "10  ac54c3ce0c9f660c03881b0668f79c60       5   \n",
       "12  0da0bcc469c2acd15350f9a8f0a74e2b       5   \n",
       "13  7d670b6c8cac0c086e21ae2f1af6eccb       4   \n",
       "\n",
       "                                          review_text  \\\n",
       "6   Remember, remember, the fifth of November. Thi...   \n",
       "8   Tinha apontado este livro como um dos que tinh...   \n",
       "10      Review coming soon! www.youtube.com/ReadTomes   \n",
       "12  What better way to celebrate Guy Fawkes Day, t...   \n",
       "13  To note - I am writing this review a quarter c...   \n",
       "\n",
       "                        date_added                    date_updated  \\\n",
       "6   Wed Jun 13 17:55:53 -0700 2012  Mon Jan 30 05:58:01 -0800 2017   \n",
       "8   Sun Jan 05 03:27:10 -0800 2014  Tue Oct 28 15:58:20 -0700 2014   \n",
       "10  Tue Feb 12 11:38:36 -0800 2013  Tue Feb 12 12:00:47 -0800 2013   \n",
       "12  Tue May 20 09:52:36 -0700 2014  Thu Mar 16 09:49:11 -0700 2017   \n",
       "13  Tue Jul 03 16:43:26 -0700 2012  Fri Feb 27 14:46:00 -0800 2015   \n",
       "\n",
       "                           read_at                      started_at  n_votes  \\\n",
       "6   Thu Jun 14 00:00:00 -0700 2012                             NaN        7   \n",
       "8   Tue Oct 28 15:58:20 -0700 2014                             NaN        1   \n",
       "10  Tue Feb 12 12:00:47 -0800 2013  Tue Feb 12 00:00:00 -0800 2013        1   \n",
       "12  Wed Nov 05 14:22:10 -0800 2014  Wed Nov 05 00:00:00 -0800 2014        2   \n",
       "13  Tue Jan 01 00:00:00 -0800 1991                             NaN       10   \n",
       "\n",
       "    n_comments  \n",
       "6            0  \n",
       "8            0  \n",
       "10           0  \n",
       "12           0  \n",
       "13           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.head()\n",
    "\n",
    "engaged_df = review_df[(review_df['n_votes'] > 0)|(review_df['n_comments'] > 0)]\n",
    "\n",
    "engaged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm  = WordNetLemmatizer()\n",
    "\n",
    "# nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    try:\n",
    "        x = re.sub(\"n\\'t\", \" not\", x)\n",
    "        x = re.sub(\"\\'d\", \" would\", x)\n",
    "        x = re.sub(\"[^a-zA-Z0-9#]\", \" \", x)\n",
    "        x = re.sub(\"www\", \" \", x)\n",
    "        x = re.sub(\"http\", \" \", x)\n",
    "        x = re.sub(\"https\", \" \", x)\n",
    "        x = re.sub(\"com\", \" \", x)\n",
    "        x = re.sub(\"url\", \" \", x)\n",
    "        return x\n",
    "    except:\n",
    "        print(x)\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "def lemmas(x, lm, tags=['NOUN', 'ADJ']):\n",
    "    x = word_tokenize(x)\n",
    "    \n",
    "    x = [lm.lemmatize(w).lower() for w in x]\n",
    "    \n",
    "#     print(x)\n",
    "    x = nlp(\" \".join(x))\n",
    "#     x = [w for w in x if w in words]\n",
    "    x = [token.lemma_ for token in x if token.pos_ in tags or token.lemma_ in words]\n",
    "    x = [w for w in x if not w.lower() in stop_words]\n",
    "    x = [w for w in x if len(w) > 2]\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanma\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "engaged_df['clean_reviews'] = engaged_df['review_text'].apply(lambda x: preprocess(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanma\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "engaged_df['clean_reviews'] = engaged_df['clean_reviews'].apply(lambda x: lemmas(x, lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                        | 0/39787 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(engaged_df['clean_reviews'])\n",
    "\n",
    "doc_term_matrix = tqdm([dictionary.doc2bow(rev) for rev in engaged_df['clean_reviews']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, doc_term_matrix, doc_clean, stop, start=2, step=1):\n",
    "    \"\"\"\n",
    "    Input   : dictionary : Gensim dictionary\n",
    "              corpus : Gensim corpus\n",
    "              texts : List of input texts\n",
    "              stop : Max num of topics\n",
    "    purpose : Compute c_v coherence for various number of topics\n",
    "    Output  : model_list : List of LSA topic models\n",
    "              coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in tqdm(range(start, stop, step)):\n",
    "        # generate LSA model\n",
    "        model = LsiModel(doc_term_matrix, num_topics=number_of_topics, id2word = dictionary)  # train model\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=doc_clean, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:49<00:00, 22.99s/it]\n"
     ]
    }
   ],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary, doc_term_matrix, engaged_df['clean_reviews'], 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 39787/39787 [00:03<00:00, 11458.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lsi = LsiModel(doc_term_matrix, num_topics=number_of_topics, id2word = dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.309*\"story\" + 0.280*\"book\" + 0.239*\"like\" + 0.238*\"read\" + 0.218*\"one\" + 0.194*\"character\" + 0.171*\"get\" + 0.150*\"really\" + 0.145*\"make\" + 0.139*\"love\"'),\n",
       " (1,\n",
       "  '0.760*\"book\" + -0.354*\"volume\" + 0.233*\"read\" + -0.222*\"story\" + -0.208*\"character\" + -0.157*\"series\" + 0.107*\"novel\" + 0.102*\"graphic\" + -0.093*\"get\" + -0.073*\"love\"'),\n",
       " (2,\n",
       "  '0.674*\"batman\" + 0.504*\"story\" + -0.204*\"volume\" + 0.171*\"joker\" + -0.150*\"like\" + -0.134*\"love\" + -0.130*\"series\" + -0.128*\"read\" + -0.104*\"get\" + 0.100*\"dark\"'),\n",
       " (3,\n",
       "  '-0.595*\"story\" + 0.340*\"batman\" + -0.294*\"novel\" + -0.270*\"graphic\" + 0.267*\"like\" + -0.224*\"read\" + 0.142*\"get\" + -0.138*\"love\" + 0.112*\"one\" + 0.092*\"know\"'),\n",
       " (4,\n",
       "  '-0.517*\"read\" + -0.456*\"batman\" + 0.341*\"story\" + -0.247*\"volume\" + -0.232*\"novel\" + -0.213*\"graphic\" + -0.167*\"love\" + 0.154*\"book\" + -0.129*\"series\" + 0.102*\"like\"')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
